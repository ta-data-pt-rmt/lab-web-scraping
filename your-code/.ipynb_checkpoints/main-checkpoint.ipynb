{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools or clicking in 'Inspect' on any browser. Here is an example:\n",
    "\n",
    "![title](example_1.png)\n",
    "\n",
    "2. Use BeautifulSoup `find_all()` to extract all the html elements that contain the developer names. Hint: pass in the `attrs` parameter to specify the class.\n",
    "\n",
    "3. Loop through the elements found and get the text for each of them.\n",
    "\n",
    "4. While you are at it, use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names. Hint: you may also use `.get_text()` instead of `.text` and pass in the desired parameters to do some string manipulation (check the documentation).\n",
    "\n",
    "5. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Trending  developers on GitHub today · GitHub</title>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "soup = BeautifulSoup(response.content)\n",
    "#print(soup.prettify())\n",
    "\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seth Vargo', 'dgtlmoon', 'Stan Girard', 'Harrison Chase', 'Travis Cline', 'Martin Geisler', 'Vadim Korolik', 'Clement Tsang', 'Saleem Abdulrasool', 'Vaibhav Srivastav', 'Liam DeBeasi', 'Brian Smith', 'JJ Kasper', 'Eugene Yurtsev', 'Ashok Menon', 'Oscar Dowson', 'David Fowler', 'Mattias Wadman', 'Marvin Hagemeister', 'Matthias Fey', 'James Newton-King', 'Alon Zakai', 'Nathan Rajlich', 'James', 'Amir Raminfar']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "names = soup.find_all('h1', class_='h3 lh-condensed')\n",
    "\n",
    "names_list = []\n",
    "\n",
    "for element in names:\n",
    "    name = element.get_text(strip=True)\n",
    "    names_list.append(name)\n",
    "\n",
    "print(names_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epfLLM /meditron', 'comfyanonymous /ComfyUI', 'openai /openai-python', 'lllyasviel /Fooocus', 'roboflow /multimodal-maestro', '521xueweihan /HelloGitHub', 'danswer-ai /danswer', 'alibaba-damo-academy /FunASR', 'paperless-ngx /paperless-ngx', 'yogeshojha /rengine', 'secdev /scapy', 'OthersideAI /self-operating-computer', 'iterative /dvc', 'srbhr /Resume-Matcher', 'graphdeco-inria /gaussian-splatting', 'hiyouga /LLaMA-Factory', 'NVIDIA /Megatron-LM', 'pytorch /pytorch', 'plenumlab /rce-finder', 'IEIT-Yuan /Yuan-2.0', 'QwenLM /Qwen', 'keras-team /keras', 'mit-han-lab /streaming-llm', 'aladdinpersson /Machine-Learning-Collection', 'JoeanAmier /XHS-Downloader']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "url = 'https://github.com/trending/python?since=daily'\n",
    "# your code here\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "\n",
    "repo = soup.find_all('h2',  class_='h3 lh-condensed')\n",
    "repos_list = []\n",
    "\n",
    "for element in repo:\n",
    "    repo_name= element.get_text(strip=True)\n",
    "    repos_list.append(repo_name)\n",
    "\n",
    "print(repos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display all the image links from Walt Disney wikipedia page.\n",
    "Hint: use `.get()` to access information inside tags. Check out the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_Disney = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "response_d = requests.get(url_Disney)\n",
    "soup = BeautifulSoup(response_d.content, 'html.parser')\n",
    "\n",
    "images = soup.find('img', class_='mw-file-element')\n",
    "\n",
    "image_url = images.get('src')\n",
    "\n",
    "\n",
    "\n",
    "print(image_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_lan = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English 6 751 000+\n",
      "Русский 1 949 000+\n",
      "Español 1 909 000+\n",
      "日本語 1 394 000+\n",
      "Deutsch 2 856 000+\n",
      "Français 2 571 000+\n",
      "Italiano 1 837 000+\n",
      "中文 1 389 000+\n",
      "العربية العربية\n",
      "فارسی فارسی\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "response_l = requests.get(url_lan)\n",
    "soup = BeautifulSoup(response_l.content, 'html.parser')\n",
    "\n",
    "lan_bloq = soup.find_all('div', class_='central-featured-lang')\n",
    "\n",
    "\n",
    "for element in lan_bloq:\n",
    "    lan_name = element.find('strong').get_text(strip=True)\n",
    "    articles_lan = element.find('bdi').get_text(strip=True)\n",
    "    print(f'{lan_name} {articles_lan}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Display the top 10 languages by number of native speakers stored in a pandas dataframe.\n",
    "Hint: After finding the correct table you want to analyse, you can use a nested **for** loop to find the elements row by row (check out the 'td' and 'tr' tags). <br>An easier way to do it is using pd.read_html(), check out documentation [here](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_list = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Language  Native speakers(millions) Language family        Branch\n",
      "0  Mandarin Chinese                      939.0    Sino-Tibetan       Sinitic\n",
      "1           Spanish                      485.0   Indo-European       Romance\n",
      "2           English                      380.0   Indo-European      Germanic\n",
      "3             Hindi                      345.0   Indo-European    Indo-Aryan\n",
      "4        Portuguese                      236.0   Indo-European       Romance\n",
      "5           Bengali                      234.0   Indo-European    Indo-Aryan\n",
      "6           Russian                      147.0   Indo-European  Balto-Slavic\n",
      "7          Japanese                      123.0         Japonic      Japanese\n",
      "8       Yue Chinese                       86.1    Sino-Tibetan       Sinitic\n",
      "9        Vietnamese                       85.0   Austroasiatic        Vietic\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "tables = pd.read_html(url_list)\n",
    "\n",
    "data = tables[0]\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe.\n",
    "Hint: If you hover over the title of the movie, you should see the director's name. Can you find where it's stored in the html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# This is the url you will scrape in this exercise \n",
    "url_im = 'https://www.imdb.com/chart/top'\n",
    "\n",
    "headers= {'Accept-Encoding':'gzip, deflate',\n",
    "          'Accept-Language':'en-US,en;q=0.9',\n",
    "          'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36'}\n",
    "response = requests.get(url_im, headers = headers)\n",
    "response.status_code\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1994', '2h 22m', 'R', '1972', '2h 55m', 'R', '2008', '2h 32m', 'PG-13', '1974', '3h 22m', 'R', '1957', '1h 36m', 'Approved', '1993', '3h 15m', 'R', '2003', '3h 21m', 'PG-13', '1994', '2h 34m', 'R', '2001', '2h 58m', 'PG-13', '1966', '2h 58m', 'Approved', '1994', '2h 22m', 'PG-13', '1999', '2h 19m', 'R', '2002', '2h 59m', 'PG-13', '2010', '2h 28m', 'PG-13', '1980', '2h 4m', 'PG', '1999', '2h 16m', 'R', '1990', '2h 25m', 'R', '1975', '2h 13m', 'R', '1995', '2h 7m', 'R', '1946', '2h 10m', 'PG', '1954', '3h 27m', 'Not Rated', '2014', '2h 49m', 'PG-13', '1991', '1h 58m', 'R', '1998', '2h 49m', 'R', '2002', '2h 10m', 'R', '1997', '1h 56m', 'PG-13', '1999', '3h 9m', 'R', '2023', '2h 20m', 'PG', '1977', '2h 1m', 'PG', '1991', '2h 17m', 'R', '1985', '1h 56m', 'PG', '2001', '2h 5m', 'PG', '2002', '2h 30m', 'R', '1960', '1h 49m', 'R', '2019', '2h 12m', 'R', '2000', '2h 35m', 'R', '1994', '1h 28m', 'G', '1994', '1h 50m', 'R', '1998', '1h 59m', 'R', '2006', '2h 31m', 'R', '2014', '1h 46m', 'R', '2006', '2h 10m', 'PG-13', '1988', '1h 29m', 'Not Rated', '1995', '1h 46m', 'R', '1962', '2h 13m', 'Not Rated', '1942', '1h 42m', 'PG', '2011', '1h 52m', 'R', '1936', '1h 27m', 'G', '1988', '2h 35m', 'PG', '1968', '2h 46m', 'PG-13', '1954', '1h 52m', 'PG', '1979', '1h 57m', 'R', '1931', '1h 27m', 'G', '1979', '2h 27m', 'R', '2012', '2h 45m', 'R', '2000', '1h 53m', 'R', '1981', '1h 55m', 'PG', '2008', '1h 38m', 'G', '2006', '2h 17m', 'R', '1950', '1h 50m', 'Passed', '2023', '3h', 'R', '1957', '1h 28m', 'Approved', '2018', '2h 29m', 'PG-13', '1980', '2h 26m', 'R', '2018', '1h 57m', 'PG', '1940', '2h 5m', 'G', '1957', '1h 56m', 'Approved', '1986', '2h 17m', 'R', '2009', '2h 33m', 'R', '2012', '2h 44m', 'PG-13', '1999', '2h 2m', 'R', '1964', '1h 35m', 'PG', '2003', '2h', 'R', '2017', '1h 45m', 'PG', '1984', '2h 40m', 'PG', '1995', '1h 21m', 'G', '1981', '2h 29m', '1995', '2h 58m', 'R', '2019', '3h 1m', 'PG-13', '2019', '2h 2m', 'R', '1997', '2h 14m', 'PG-13', '1997', '2h 6m', 'R', '2016', '1h 46m', 'TV-PG', '1984', '3h 49m', 'R', '1963', '2h 23m', 'Not Rated', '2009', '2h 50m', 'PG-13', '1952', '1h 43m', 'G', '2018', '2h 6m', 'R', '2000', '1h 42m', 'Unrated', '1985', '2h 22m', 'Not Rated', '2010', '1h 43m', 'G', '1983', '2h 11m', 'PG', '2004', '1h 48m', 'R', '1968', '2h 29m', 'G', '2012', '1h 55m', 'R', '1992', '1h 39m', 'R', '1952', '2h 23m', 'Not Rated', '1962', '3h 38m', 'Approved', '1960', '2h 5m', 'Approved', '1941', '1h 59m', 'PG', '1931', '1h 39m', 'Passed', '1959', '2h 16m', 'Approved', '1958', '2h 8m', 'PG', '1944', '1h 47m', 'Passed', '2001', '2h 2m', 'R', '1983', '2h 50m', '18+', '1987', '1h 56m', 'R', '2010', '2h 11m', 'R', '1971', '2h 16m', 'X', '1995', '2h 50m', 'R', '2009', '1h 36m', 'PG', '1962', '2h 9m', 'Approved', '2020', '2h 40m', 'PG-13', '1973', '2h 9m', 'PG', '2011', '2h 3m', 'PG-13', '1989', '2h 7m', 'PG-13', '1927', '2h 33m', 'Not Rated', '1988', '2h 12m', 'R', '2007', '2h 42m', 'PG', '2000', '1h 42m', 'R', '1948', '1h 29m', 'Not Rated', '1997', '2h 18m', 'R', '1976', '1h 54m', 'R', '2019', '1h 59m', 'R', '2004', '2h 36m', 'R', '2016', '2h 41m', 'Not Rated', '1965', '2h 12m', 'R', '2005', '2h 20m', 'PG-13', '2022', '2h 10m', 'PG-13', '1959', '2h 1m', 'Passed', '1921', '1h 8m', 'Passed', '2013', '3h', 'R', '2020', '1h 37m', 'PG-13', '2018', '2h 10m', 'PG-13', '1950', '2h 18m', 'Passed', '1961', '2h 59m', 'Approved', '1998', '1h 43m', 'PG', '2007', '2h 38m', 'R', '1995', '2h 58m', 'R', '2010', '2h 18m', 'R', '1985', '2h 40m', 'R', '2006', '1h 58m', 'R', '1993', '2h 7m', 'PG-13', '1999', '1h 47m', 'PG-13', '1992', '2h 10m', 'R', '2001', '2h 15m', 'PG-13', '2007', '2h 2m', 'R', '1948', '2h 6m', 'Passed', '1961', '1h 50m', 'Not Rated', '2003', '1h 51m', 'R', '1982', '1h 49m', 'R', '1975', '1h 31m', 'PG', '1963', '2h 52m', 'Approved', '2003', '1h 40m', 'G', '1950', '1h 28m', 'Not Rated', '1980', '2h 4m', 'PG', '1974', '2h 10m', 'R', '2004', '1h 59m', 'PG', '1954', '1h 45m', 'PG', '1939', '3h 58m', 'Passed', '2005', '2h 12m', 'R', '2013', '2h 33m', 'R', '1980', '2h 9m', 'R', '1998', '1h 47m', 'R', '2009', '2h 9m', 'R', '2015', '1h 35m', 'PG', '2021', '2h 28m', 'PG-13', '2017', '1h 55m', 'R', '1996', '1h 33m', 'R', '1957', '2h 41m', 'PG', '1996', '1h 38m', 'R', '2011', '2h 20m', 'PG-13', '2002', '2h 21m', 'PG-13', '2008', '1h 56m', 'R', '2019', '1h 36m', 'PG', '1988', '1h 26m', 'G', '2004', '2h 12m', 'PG-13', '2011', '2h 10m', 'PG-13', '1997', '1h 29m', 'PG', '1982', '1h 57m', 'R', '2013', '2h 14m', 'R', '1995', '1h 41m', 'R', '2014', '1h 39m', 'R', '1959', '3h 32m', 'G', '1925', '1h 35m', 'Passed', '1975', '3h 5m', 'PG', '2014', '2h 29m', 'R', '2016', '2h 19m', 'R', '1993', '2h 13m', 'R', '1954', '1h 48m', 'Approved', '2003', '2h 12m', 'Not Rated', '1926', '1h 18m', 'Passed', '1978', '3h 3m', 'R', '2014', '2h 2m', 'R', '1957', '1h 31m', 'Not Rated', '1989', '2h 8m', 'PG', '1949', '1h 33m', 'Approved', '1953', '2h 11m', 'Not Rated', '2015', '2h', 'R', '1924', '45m', 'Passed', '2001', '1h 32m', 'G', '1939', '2h 9m', 'Passed', '1975', '2h 4m', 'PG', '2010', '1h 38m', 'PG', '2009', '1h 32m', 'Not Rated', '2019', '2h 32m', 'PG-13', '1957', '1h 36m', 'Not Rated', '2015', '1h 58m', 'R', '1998', '1h 57m', 'R', '2007', '1h 51m', 'G', '1953', '2h 16m', 'Not Rated', '1976', '2h', 'PG', '2004', '2h 1m', 'PG-13', '2017', '2h 17m', 'R', '2015', '2h 9m', 'R', '1986', '2h', 'R', '1928', '1h 54m', 'Passed', '1984', '1h 47m', 'R', '2021', '2h 44m', 'TV-MA', '2004', '1h 20m', 'R', '2013', '2h 3m', 'R', '1976', '2h 1m', 'R', '1973', '2h 2m', 'R', '1946', '2h 50m', 'Approved', '1986', '1h 29m', 'R', '1995', '1h 38m', 'Not Rated', '2003', '2h 23m', 'PG-13', '1939', '1h 42m', 'G', '2004', '1h 55m', 'PG', '2007', '2h 28m', 'R', '2009', '1h 33m', 'G', '1942', '1h 39m', 'Passed', '2016', '2h 25m', 'Not Rated', '2005', '1h 52m', 'Not Rated', '1993', '1h 41m', 'PG', '1966', '2h 1m', 'Not Rated', '1940', '2h 9m', 'Passed', '2000', '2h 34m', 'R', '1965', '2h 52m', 'G', '1940', '2h 10m', 'Approved', '1967', '2h 7m', 'GP', '1999', '1h 26m', 'PG', '1955', '2h 5m', 'Not Rated', '2011', '2h 26m', 'PG-13', '1934', '1h 45m', 'Passed', '1959', '1h 39m', 'Not Rated', '1992', '1h 30m', 'G', '1990', '3h 1m', 'PG-13', '1979', '1h 34m', 'R', '1966', '1h 23m', 'Not Rated']\n",
      "['IMDb Charts', '1. The Shawshank Redemption', '2. The Godfather', '3. The Dark Knight', '4. The Godfather Part II', '5. 12 Angry Men', \"6. Schindler's List\", '7. The Lord of the Rings: The Return of the King', '8. Pulp Fiction', '9. The Lord of the Rings: The Fellowship of the Ring', '10. The Good, the Bad and the Ugly', '11. Forrest Gump', '12. Fight Club', '13. The Lord of the Rings: The Two Towers', '14. Inception', '15. Star Wars: Episode V - The Empire Strikes Back', '16. The Matrix', '17. Goodfellas', \"18. One Flew Over the Cuckoo's Nest\", '19. Se7en', \"20. It's a Wonderful Life\", '21. Seven Samurai', '22. Interstellar', '23. The Silence of the Lambs', '24. Saving Private Ryan', '25. City of God', '26. Life Is Beautiful', '27. The Green Mile', '28. Spider-Man: Across the Spider-Verse', '29. Star Wars: Episode IV - A New Hope', '30. Terminator 2: Judgment Day', '31. Back to the Future', '32. Spirited Away', '33. The Pianist', '34. Psycho', '35. Parasite', '36. Gladiator', '37. The Lion King', '38. Léon: The Professional', '39. American History X', '40. The Departed', '41. Whiplash', '42. The Prestige', '43. Grave of the Fireflies', '44. The Usual Suspects', '45. Harakiri', '46. Casablanca', '47. The Intouchables', '48. Modern Times', '49. Cinema Paradiso', '50. Once Upon a Time in the West', '51. Rear Window', '52. Alien', '53. City Lights', '54. Apocalypse Now', '55. Django Unchained', '56. Memento', '57. Raiders of the Lost Ark', '58. WALL·E', '59. The Lives of Others', '60. Sunset Blvd.', '61. Oppenheimer', '62. Paths of Glory', '63. Avengers: Infinity War', '64. The Shining', '65. Spider-Man: Into the Spider-Verse', '66. The Great Dictator', '67. Witness for the Prosecution', '68. Aliens', '69. Inglourious Basterds', '70. The Dark Knight Rises', '71. American Beauty', '72. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb', '73. Oldboy', '74. Coco', '75. Amadeus', '76. Toy Story', '77. Das Boot', '78. Braveheart', '79. Avengers: Endgame', '80. Joker', '81. Princess Mononoke', '82. Good Will Hunting', '83. Your Name.', '84. Once Upon a Time in America', '85. High and Low', '86. 3 Idiots', \"87. Singin' in the Rain\", '88. Capernaum', '89. Requiem for a Dream', '90. Come and See', '91. Toy Story 3', '92. Star Wars: Episode VI - Return of the Jedi', '93. Eternal Sunshine of the Spotless Mind', '94. 2001: A Space Odyssey', '95. The Hunt', '96. Reservoir Dogs', '97. Ikiru', '98. Lawrence of Arabia', '99. The Apartment', '100. Citizen Kane', '101. M', '102. North by Northwest', '103. Vertigo', '104. Double Indemnity', '105. Amélie', '106. Scarface', '107. Full Metal Jacket', '108. Incendies', '109. A Clockwork Orange', '110. Heat', '111. Up', '112. To Kill a Mockingbird', '113. Hamilton', '114. The Sting', '115. A Separation', '116. Indiana Jones and the Last Crusade', '117. Metropolis', '118. Die Hard', '119. Like Stars on Earth', '120. Snatch', '121. Bicycle Thieves', '122. L.A. Confidential', '123. Taxi Driver', '124. 1917', '125. Downfall', '126. Dangal', '127. For a Few Dollars More', '128. Batman Begins', '129. Top Gun: Maverick', '130. Some Like It Hot', '131. The Kid', '132. The Wolf of Wall Street', '133. The Father', '134. Green Book', '135. All About Eve', '136. Judgment at Nuremberg', '137. The Truman Show', '138. There Will Be Blood', '139. Casino', '140. Shutter Island', '141. Ran', \"142. Pan's Labyrinth\", '143. Jurassic Park', '144. The Sixth Sense', '145. Unforgiven', '146. A Beautiful Mind', '147. No Country for Old Men', '148. The Treasure of the Sierra Madre', '149. Yojimbo', '150. Kill Bill: Vol. 1', '151. The Thing', '152. Monty Python and the Holy Grail', '153. The Great Escape', '154. Finding Nemo', '155. Rashomon', '156. The Elephant Man', '157. Chinatown', \"158. Howl's Moving Castle\", '159. Dial M for Murder', '160. Gone with the Wind', '161. V for Vendetta', '162. Prisoners', '163. Raging Bull', '164. Lock, Stock and Two Smoking Barrels', '165. The Secret in Their Eyes', '166. Inside Out', '167. Spider-Man: No Way Home', '168. Three Billboards Outside Ebbing, Missouri', '169. Trainspotting', '170. The Bridge on the River Kwai', '171. Fargo', '172. Warrior', '173. Catch Me If You Can', '174. Gran Torino', '175. Klaus', '176. My Neighbor Totoro', '177. Million Dollar Baby', '178. Harry Potter and the Deathly Hallows: Part 2', '179. Children of Heaven', '180. Blade Runner', '181. 12 Years a Slave', '182. Before Sunrise', '183. The Grand Budapest Hotel', '184. Ben-Hur', '185. The Gold Rush', '186. Barry Lyndon', '187. Gone Girl', '188. Hacksaw Ridge', '189. In the Name of the Father', '190. On the Waterfront', '191. Memories of Murder', '192. The General', '193. The Deer Hunter', '194. Wild Tales', '195. Wild Strawberries', '196. Dead Poets Society', '197. The Third Man', '198. The Wages of Fear', '199. Mad Max: Fury Road', '200. Sherlock Jr.', '201. Monsters, Inc.', '202. Mr. Smith Goes to Washington', '203. Jaws', '204. How to Train Your Dragon', '205. Mary and Max', '206. Ford v Ferrari', '207. The Seventh Seal', '208. Room', '209. The Big Lebowski', '210. Ratatouille', '211. Tokyo Story', '212. Rocky', '213. Hotel Rwanda', '214. Logan', '215. Spotlight', '216. Platoon', '217. The Passion of Joan of Arc', '218. The Terminator', '219. Jai Bhim', '220. Before Sunset', '221. Rush', '222. Network', '223. The Exorcist', '224. The Best Years of Our Lives', '225. Stand by Me', '226. La haine', '227. Pirates of the Caribbean: The Curse of the Black Pearl', '228. The Wizard of Oz', '229. The Incredibles', '230. Into the Wild', \"231. Hachi: A Dog's Tale\", '232. To Be or Not to Be', '233. The Handmaiden', '234. My Father and My Son', '235. Groundhog Day', '236. The Battle of Algiers', '237. The Grapes of Wrath', '238. Amores Perros', '239. The Sound of Music', '240. Rebecca', '241. Cool Hand Luke', '242. The Iron Giant', '243. Pather Panchali', '244. The Help', '245. It Happened One Night', '246. The 400 Blows', '247. Aladdin', '248. Dances with Wolves', '249. Life of Brian', '250. Persona', 'You have rated', 'More to explore', 'Charts', 'Top Box Office (US)', 'Most Popular Movies', 'Top Rated English Movies', 'Most Popular TV Shows', 'Top 250 TV Shows', 'Lowest Rated Movies', 'Most Popular Celebs', 'Top Rated Movies by Genre', 'Recently viewed']\n",
      "['9.3(2.8M)', '9.2(2M)', '9.0(2.8M)', '9.0(1.3M)', '9.0(842K)', '9.0(1.4M)', '9.0(1.9M)', '8.9(2.2M)', '8.8(2M)', '8.8(796K)', '8.8(2.2M)', '8.8(2.3M)', '8.8(1.7M)', '8.8(2.5M)', '8.7(1.4M)', '8.7(2M)', '8.7(1.2M)', '8.7(1.1M)', '8.6(1.8M)', '8.6(483K)', '8.6(361K)', '8.7(2M)', '8.6(1.5M)', '8.6(1.5M)', '8.6(787K)', '8.6(729K)', '8.6(1.4M)', '8.7(304K)', '8.6(1.4M)', '8.6(1.2M)', '8.5(1.3M)', '8.6(821K)', '8.5(888K)', '8.5(706K)', '8.5(906K)', '8.5(1.6M)', '8.5(1.1M)', '8.5(1.2M)', '8.5(1.2M)', '8.5(1.4M)', '8.5(948K)', '8.5(1.4M)', '8.5(300K)', '8.5(1.1M)', '8.6(65K)', '8.5(596K)', '8.5(908K)', '8.5(255K)', '8.5(277K)', '8.5(344K)', '8.5(513K)', '8.5(929K)', '8.5(193K)', '8.4(697K)', '8.5(1.7M)', '8.4(1.3M)', '8.4(1M)', '8.4(1.2M)', '8.4(404K)', '8.4(232K)', '8.5(527K)', '8.4(208K)', '8.4(1.2M)', '8.4(1.1M)', '8.4(643K)', '8.4(234K)', '8.4(134K)', '8.4(749K)', '8.4(1.5M)', '8.4(1.8M)', '8.3(1.2M)', '8.4(510K)', '8.4(618K)', '8.4(566K)', '8.4(420K)', '8.3(1M)', '8.4(261K)', '8.3(1.1M)', '8.4(1.2M)', '8.4(1.4M)', '8.3(421K)', '8.3(1M)', '8.4(305K)', '8.3(370K)', '8.4(51K)', '8.4(422K)', '8.3(255K)', '8.4(101K)', '8.3(882K)', '8.4(92K)', '8.3(876K)', '8.3(1.1M)', '8.3(1.1M)', '8.3(705K)', '8.3(354K)', '8.3(1.1M)', '8.3(85K)', '8.3(308K)', '8.3(192K)', '8.3(459K)', '8.3(166K)', '8.3(341K)', '8.3(420K)', '8.3(165K)', '8.3(783K)', '8.3(894K)', '8.3(776K)', '8.3(192K)', '8.3(866K)', '8.3(701K)', '8.3(1.1M)', '8.3(328K)', '8.3(108K)', '8.3(275K)', '8.3(255K)', '8.2(797K)', '8.3(182K)', '8.2(920K)', '8.3(203K)', '8.2(893K)', '8.3(172K)', '8.2(606K)', '8.2(896K)', '8.2(652K)', '8.2(369K)', '8.3(204K)', '8.2(269K)', '8.2(1.5M)', '8.3(644K)', '8.2(279K)', '8.2(133K)', '8.2(1.5M)', '8.2(182K)', '8.2(544K)', '8.2(137K)', '8.3(83K)', '8.2(1.2M)', '8.2(627K)', '8.2(551K)', '8.2(1.4M)', '8.2(133K)', '8.2(693K)', '8.2(1M)', '8.2(1M)', '8.2(429K)', '8.2(970K)', '8.2(1M)', '8.2(131K)', '8.2(129K)', '8.2(1.2M)', '8.2(455K)', '8.2(562K)', '8.2(255K)', '8.2(1.1M)', '8.2(177K)', '8.2(254K)', '8.2(343K)', '8.2(431K)', '8.2(185K)', '8.2(329K)', '8.2(1.2M)', '8.1(782K)', '8.1(373K)', '8.1(607K)', '8.2(219K)', '8.1(764K)', '8.2(846K)', '8.1(542K)', '8.1(714K)', '8.1(230K)', '8.1(709K)', '8.1(491K)', '8.1(1.1M)', '8.1(803K)', '8.2(175K)', '8.1(367K)', '8.1(712K)', '8.1(926K)', '8.2(79K)', '8.1(807K)', '8.1(730K)', '8.1(331K)', '8.1(867K)', '8.1(250K)', '8.1(117K)', '8.1(179K)', '8.1(1M)', '8.1(576K)', '8.1(184K)', '8.1(162K)', '8.1(207K)', '8.1(96K)', '8.1(355K)', '8.1(212K)', '8.1(113K)', '8.1(529K)', '8.1(179K)', '8.2(65K)', '8.1(1.1M)', '8.2(55K)', '8.1(958K)', '8.1(120K)', '8.1(646K)', '8.1(782K)', '8.1(184K)', '8.1(446K)', '8.1(195K)', '8.1(442K)', '8.1(845K)', '8.1(799K)', '8.1(67K)', '8.1(616K)', '8.1(368K)', '8.1(811K)', '8.1(493K)', '8.1(431K)', '8.1(59K)', '8.1(907K)', '8.8(213K)', '8.1(282K)', '8.1(504K)', '8.1(167K)', '8.1(445K)', '8.1(69K)', '8.1(431K)', '8.1(190K)', '8.1(1.2M)', '8.1(420K)', '8.0(788K)', '8.1(648K)', '8.1(304K)', '8.2(42K)', '8.1(166K)', '8.2(91K)', '8.0(669K)', '8.1(64K)', '8.1(98K)', '8.1(250K)', '8.1(252K)', '8.1(144K)', '8.1(186K)', '8.1(219K)', '8.2(37K)', '8.1(483K)', '8.1(110K)', '8.1(126K)', '8.0(454K)', '8.0(284K)', '8.0(417K)', '8.1(128K)']\n"
     ]
    }
   ],
   "source": [
    "titles = soup.find_all('h3', class_='ipc-title__text')\n",
    "years = soup.find_all('span', class_='sc-479faa3c-8 bNrEFi cli-title-metadata-item')\n",
    "##director = soup.find_all('h3', class_='ipc-title__text')\n",
    "stars = soup.find_all('span', class_='ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating')\n",
    "\n",
    "##ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating\n",
    "\n",
    "stars_list = []\n",
    "years_list = []\n",
    "movies_list = []\n",
    "for element in titles:\n",
    "    movie_name= element.get_text(strip=True)\n",
    "    movies_list.append(movie_name)\n",
    "    \n",
    "for element in years:\n",
    "    movie_year= element.get_text(strip=True)\n",
    "    years_list.append(movie_year)\n",
    "    \n",
    "    \n",
    "##for element in director:\n",
    "  ##  movie_director= element.get_text(strip=True)\n",
    "   ## directors_list.append(movie_director)\n",
    "    \n",
    "for element in stars:\n",
    "    movie_stars= element.get_text(strip=True)\n",
    "    stars_list.append(movie_stars)\n",
    "\n",
    "\n",
    "\n",
    "print(years_list)\n",
    "print(movies_list)\n",
    "print(stars_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Movie Name year_movie stars_movie\n",
      "0    1. The Shawshank Redemption       1994   9.3(2.8M)\n",
      "1               2. The Godfather       1972     9.2(2M)\n",
      "2             3. The Dark Knight       2008   9.0(2.8M)\n",
      "3       4. The Godfather Part II       1974   9.0(1.3M)\n",
      "4                5. 12 Angry Men       1957   9.0(842K)\n",
      "..                           ...        ...         ...\n",
      "245           246. The 400 Blows       1959   8.1(126K)\n",
      "246                 247. Aladdin       1992   8.0(454K)\n",
      "247      248. Dances with Wolves       1990   8.0(284K)\n",
      "248           249. Life of Brian       1979   8.0(417K)\n",
      "249                 250. Persona       1966   8.1(128K)\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Parsear el HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontrar todos los elementos con la clase \"elemento\"\n",
    "elementos = soup.select('.ipc-metadata-list-summary-item') ##cajita que tiene la info para cada peli\n",
    "\n",
    "# Crear listas para cada columna\n",
    "stars_list = []\n",
    "years_list = []\n",
    "movies_list = []\n",
    "\n",
    "# Iterar sobre los elementos y extraer la información\n",
    "for elemento in elementos:\n",
    "    # Encontrar el contenido de las etiquetas <p> dentro de cada elemento\n",
    "    name_movie = elemento.find('h3', class_='ipc-title__text').get_text(strip=True)\n",
    "    year_movie = elemento.find('span', class_='sc-479faa3c-8 bNrEFi cli-title-metadata-item').get_text(strip=True)\n",
    "    stars_movie = elemento.find('span', class_='ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating').get_text(strip=True)\n",
    "    # Agregar la información a las listas\n",
    "    movies_list.append(name_movie)\n",
    "    years_list.append(year_movie)\n",
    "    stars_list.append(stars_movie)\n",
    "\n",
    "# Crear un DataFrame con las listas\n",
    "df = pd.DataFrame({'Movie Name': movies_list, 'year_movie': years_list,'stars_movie': stars_list})\n",
    "\n",
    "# Imprimir el DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url_imdb = 'https://www.imdb.com/list/ls009796553/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Movie Name year_movie stars_movie\n",
      "0    1. The Shawshank Redemption       1994   9.3(2.8M)\n",
      "1               2. The Godfather       1972     9.2(2M)\n",
      "2             3. The Dark Knight       2008   9.0(2.8M)\n",
      "3       4. The Godfather Part II       1974   9.0(1.3M)\n",
      "4                5. 12 Angry Men       1957   9.0(842K)\n",
      "..                           ...        ...         ...\n",
      "245           246. The 400 Blows       1959   8.1(126K)\n",
      "246                 247. Aladdin       1992   8.0(454K)\n",
      "247      248. Dances with Wolves       1990   8.0(284K)\n",
      "248           249. Life of Brian       1979   8.0(417K)\n",
      "249                 250. Persona       1966   8.1(128K)\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "url_imdb = 'https://www.imdb.com/chart/top'\n",
    "\n",
    "headers= {'Accept-Encoding':'gzip, deflate',\n",
    "          'Accept-Language':'en-US,en;q=0.9',\n",
    "          'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36'}\n",
    "\n",
    "response = requests.get(url_imdb, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "# Encontrar todos los elementos con la clase \"elemento\"\n",
    "elementos = soup.select('.ipc-metadata-list-summary-item')\n",
    "\n",
    "# Crear listas para cada columna\n",
    "stars_list = []\n",
    "years_list = []\n",
    "movies_list = []\n",
    "\n",
    "# Iterar sobre los elementos y extraer la información\n",
    "for elemento in elementos:\n",
    "    # Encontrar el contenido de las etiquetas <p> dentro de cada elemento\n",
    "    name_movie = elemento.find('h3', class_='ipc-title__text').get_text(strip=True)\n",
    "    year_movie = elemento.find('span', class_='sc-479faa3c-8 bNrEFi cli-title-metadata-item').get_text(strip=True)\n",
    "    stars_movie = elemento.find('span', class_='ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating').get_text(strip=True)\n",
    "    # Agregar la información a las listas\n",
    "    movies_list.append(name_movie)\n",
    "    years_list.append(year_movie)\n",
    "    stars_list.append(stars_movie)\n",
    "\n",
    "# Crear un DataFrame con las listas\n",
    "df = pd.DataFrame({'Movie Name': movies_list, 'year_movie': years_list,'stars_movie': stars_list})\n",
    "\n",
    "# Imprimir el DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>year_movie</th>\n",
       "      <th>stars_movie</th>\n",
       "      <th>numerical_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3(2.8M)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2(2M)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0(2.8M)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0(1.3M)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. 12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>9.0(842K)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246. The 400 Blows</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.1(126K)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247. Aladdin</td>\n",
       "      <td>1992</td>\n",
       "      <td>8.0(454K)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248. Dances with Wolves</td>\n",
       "      <td>1990</td>\n",
       "      <td>8.0(284K)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249. Life of Brian</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.0(417K)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250. Persona</td>\n",
       "      <td>1966</td>\n",
       "      <td>8.1(128K)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Movie Name year_movie stars_movie  numerical_stars\n",
       "0    1. The Shawshank Redemption       1994   9.3(2.8M)              9.3\n",
       "1               2. The Godfather       1972     9.2(2M)              9.2\n",
       "2             3. The Dark Knight       2008   9.0(2.8M)              9.0\n",
       "3       4. The Godfather Part II       1974   9.0(1.3M)              9.0\n",
       "4                5. 12 Angry Men       1957   9.0(842K)              9.0\n",
       "..                           ...        ...         ...              ...\n",
       "245           246. The 400 Blows       1959   8.1(126K)              8.1\n",
       "246                 247. Aladdin       1992   8.0(454K)              8.0\n",
       "247      248. Dances with Wolves       1990   8.0(284K)              8.0\n",
       "248           249. Life of Brian       1979   8.0(417K)              8.0\n",
       "249                 250. Persona       1966   8.1(128K)              8.1\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def extraer_numero(cadena):\n",
    "    try:\n",
    "        return float(re.search(r'(\\d+\\.\\d+)', cadena).group(1))\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# Aplicar la función a la columna 'Columna'\n",
    "df['numerical_stars'] = df['stars_movie'].apply(extraer_numero)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>year_movie</th>\n",
       "      <th>stars_movie</th>\n",
       "      <th>numerical_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3(2.8M)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2(2M)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0(2.8M)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0(1.3M)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. 12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>9.0(842K)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. Schindler's List</td>\n",
       "      <td>1993</td>\n",
       "      <td>9.0(1.4M)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>9.0(1.9M)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Pulp Fiction</td>\n",
       "      <td>1994</td>\n",
       "      <td>8.9(2.2M)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>8.8(2.2M)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. The Lord of the Rings: The Two Towers</td>\n",
       "      <td>2002</td>\n",
       "      <td>8.8(1.7M)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Movie Name year_movie stars_movie  \\\n",
       "0                        1. The Shawshank Redemption       1994   9.3(2.8M)   \n",
       "1                                   2. The Godfather       1972     9.2(2M)   \n",
       "2                                 3. The Dark Knight       2008   9.0(2.8M)   \n",
       "3                           4. The Godfather Part II       1974   9.0(1.3M)   \n",
       "4                                    5. 12 Angry Men       1957   9.0(842K)   \n",
       "5                                6. Schindler's List       1993   9.0(1.4M)   \n",
       "6   7. The Lord of the Rings: The Return of the King       2003   9.0(1.9M)   \n",
       "7                                    8. Pulp Fiction       1994   8.9(2.2M)   \n",
       "10                                  11. Forrest Gump       1994   8.8(2.2M)   \n",
       "12         13. The Lord of the Rings: The Two Towers       2002   8.8(1.7M)   \n",
       "\n",
       "    numerical_stars  \n",
       "0               9.3  \n",
       "1               9.2  \n",
       "2               9.0  \n",
       "3               9.0  \n",
       "4               9.0  \n",
       "5               9.0  \n",
       "6               9.0  \n",
       "7               8.9  \n",
       "10              8.8  \n",
       "12              8.8  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.sort_values(by='numerical_stars',ascending=False, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 100 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe.\n",
    "***Hint:*** Here the displayed number of earthquakes per page is 20, but you can easily move to the next page by looping through the desired number of pages and adding it to the end of the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/?view='\n",
    "\n",
    "# This is how you will loop through each page:\n",
    "number_of_pages = int(100/20)\n",
    "each_page_urls = []\n",
    "\n",
    "for n in range(1, number_of_pages+1):\n",
    "    link = url+str(n)\n",
    "    each_page_urls.append(link)\n",
    "    \n",
    "each_page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
